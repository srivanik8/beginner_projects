{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h1 style=\"text-align: center\">\n",
    "<div style=\"color: #DD3403; font-size: 60%\">Data Science DISCOVERY MicroProject</div>\n",
    "<span style=\"\">MicroProject #5: Bechdel Test</span>\n",
    "<div style=\"font-size: 60%;\"><a href=\"https://discovery.cs.illinois.edu/microproject/bechdel-test/\">https://discovery.cs.illinois.edu/microproject/bechdel-test/</a></div>\n",
    "</h1>\n",
    "\n",
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Source: Bechdel Test\n",
    "\n",
    "The Bechdel Test is a simple way of measuring the representation of women in a film or other work of fiction.  A work earns points for each of three criteria:\n",
    "\n",
    "1. The work must have at least two women in it,\n",
    "\n",
    "2. who talk to each other,\n",
    "\n",
    "3. about something other than a man.\n",
    "\n",
    "The test was popularized by Alison Bechdel's 1985 comic strip called \"The Rule\" and has grown in popularity as a simple way to measure the representation of women in works of fiction.  The website [BechdelTest.com](BechdelTest.com) provides both a searchable database and a publicly-available API that includes over 10,000 films and their Bechdel Test ratings, allowing users to explore and analyze patterns in gender representation in cinema.\n",
    "\n",
    "In this MicroProject, you will explore using a JSON-based API, grouping data using a pivot table (`df.pivot_table(...)`), and creating a stacked area chart to create a data visualization that shows the change in Bechdel Test ratings over time.  Let's nerd out! ðŸŽ‰\n",
    "\n",
    "\n",
    "### Background Knowledge\n",
    "\n",
    "To finish this MicroProject, we assume you already know:\n",
    "\n",
    "- All topics covered in *DISCOVERY Module 1: Basics of Data Science with Python* ([review the module here](https://discovery.cs.illinois.edu/learn/))\n",
    "- Adding new rows and columns into an existing DataFrame ([review creating new columns here](https://discovery.cs.illinois.edu/guides/Modifying-DataFrames/adding-columns-in-dataframes/))\n",
    "- Grouping data in Python ([reviewing grouping data in Python](https://discovery.cs.illinois.edu/learn/Exploratory-Data-Analysis/Grouping-Data-in-Python/))\n",
    "\n",
    "Let's get started! :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1: Importing the Bechdel Test Dataset\n",
    "\n",
    "The [bechdeltest.com](http://bechdeltest.com) public API provides a easy-to-access data source that contains the Bechdel Test ratings for thousands of movies.  Through reading the technical API documentation at [https://bechdeltest.com/api/v1/doc](https://bechdeltest.com/api/v1/doc), you can find that:\n",
    "\n",
    "- The Bechdel Test API uses the JSON format (which can be read into a DataFrame using `pd.read_json(...)`), and \n",
    "\n",
    "- The URL endpoint for the list of all movies is `https://bechdeltest.com/api/v1/getAllMovies`.\n",
    "\n",
    "Using `pd.read_json`, create a DataFrame `df_bechdel` to store all the movies and their Bechdel Test ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of all movies and their Bechdel Test scores by using pd.read_json()\n",
    "# to read the API endpoint:\n",
    "#    https://bechdeltest.com/api/v1/getAllMovies\n",
    "\n",
    "df_bechdel = ...\n",
    "df_bechdel"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning the Dataset\n",
    "\n",
    "The DataFrame you collected comes from BechdelTest.com, containing their collection of data.  As with many real data sources, there may be typos, errors, or incorrect values in the data.\n",
    "\n",
    "For example, the 2000 film *[\"Grandma Got Run Over by a Reindeer\"](https://www.imdb.com/title/tt0267536/)* was incorrectly listed as being released in the year 200 instead of 2000 -- that's a big difference!!  (*This specific error may have been fixed by BechdelTest.com when you're doing the MicroProject, or there may be others*.)\n",
    "\n",
    "Additionally, many of the early films in the dataset, including 1874's *[\"Passage de Venus\"](https://www.imdb.com/title/tt3155794/)*, are technical films at the very beginning of \"motion pictures\".  *Passage de Venus*, for example, is a six-second film showing Venus pass between the Earth and the Sun and not a work of fiction that would be traditionally analyzed using the Bechdel Test.\n",
    "\n",
    "To limit our data to modern film and remove any erroneous data, create a new DataFrame `df_clean` that contains the data from `df_bechdel` where:\n",
    "\n",
    "1. All movies made before 1900 are removed.  *(The data in `df_clean` should only be movies made in 1900 or later.)*\n",
    "2. All movies made in the future are removed.  *(It's impossible to have a movie from 2035 in 2025.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame `df_clean` from `df_bechdel` with only movies made in/after 1900 AND not in the future:\n",
    "df_clean = ...\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 1: Importing the Bechdel Test Dataset\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "import datetime\n",
    "assert( \"df_bechdel\" in vars() ), \"You must define a Python variable named `df_bechdel`.\"\n",
    "assert( \"df_clean\" in vars() ), \"You must define a Python variable named `df_clean`.\"\n",
    "assert( \"year\" in df_bechdel ), \"The DataFrame stored in the variable `df_bechdel` must come from the BechdelTest.com API.\"\n",
    "assert( len(df_bechdel.columns) == len(df_clean.columns) ), \"The DataFrames `df_bechdel` and `df_clean` must both be data from the BechdelTest.com API.\"\n",
    "assert( df_bechdel.year.min() < 1900 ), \"The DataFrame `df_bechdel` must contain ALL data from the BechdelTest.com API; only `df_clean` should contain the filtered data.\"\n",
    "assert( df_clean.year.min() == 1900 ), \"The DataFrame `df_clean` must NOT contain any movies made before 1900.\"\n",
    "assert( df_clean.year.max() <= datetime.datetime.now().year ), \"The DataFrame `df_clean` must NOT contain any movies in the future.\"\n",
    "assert( len(df_bechdel) > len(df_clean) ), \"The DataFrame `df_bechdel` must have more rows than the filtered DataFrame `df_clean`.\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Creating a Pivot Table for Analysis\n",
    "\n",
    "With over 10,000 movies that were released over 100 years, creating a summary of our data may be helpful for analysis!  Specifically, it would be very useful to get a breakdown of the **number of movies for each Bechdel Test rating from every year**.\n",
    "\n",
    "In the simplest terms, we would crete a dataset with the following overall structure:\n",
    "- In 1900, there were 11 movies all with a `0` score.\n",
    "- In 1910, there were 2 movies with a `0` score and 1 movie with a `3` score.\n",
    "- In 1989, there were 81 movies; 12 with a `0`, 16 with a `1`, 11 with a `2`, and 41 with a `3` score.\n",
    "\n",
    "Translating this design idea to a table, a simple design for the table would have:\n",
    "- Each **row** of our table to be a year,\n",
    "- Each **column** of our table to be a score (0, 1, 2, and 3),  **AND**\n",
    "- The **values** inside of our table to **count** the number of times a movie was made in that year with that specific rating.\n",
    "\n",
    "That means the table would look something like:\n",
    "\n",
    "| Year | 0 | 1 | 2 | 3 |\n",
    "| ---- | - | - | - | - |\n",
    "| 1900 | 11 | 0 | 0 | 0 |\n",
    "| ... |\n",
    "| 1910 | 2 | 0 | 0 | 1 |\n",
    "| ... |\n",
    "| 1989 | 12 | 16 | 11 | 41 |\n",
    "| ... |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2.1: Starting a Pivot Table with `index` and `aggfunc`:\n",
    "\n",
    "The **groupby** and **pivot table** operations are two different ways to summarize a DataFrame using pandas.  In general, the `groupby` operation resembles how databases work and the `pivot_table` operation resembles how spreadsheets works, but both methods can create almost any summary of data!\n",
    "\n",
    "To make a **pivot table**, you specify the structure of the table you want pandas to generate along with how you want multiple rows to be combined (or aggregated) together.\n",
    "\n",
    "The simplest of pivot tables require us two specify only two things:\n",
    "\n",
    "1. What column name in our original DataFrame do we want to use for the row labels for our pivot table?  (*This is called the `index` in a pivot table.*)\n",
    "2. How do we want to combine multiple rows together?  (*This is called the `aggfunc` in a pivot table.*)\n",
    "\n",
    "For example, if we want to **count** the number of movies with unique values for **`rating`**, our initial pivot table can be created using the following code:\n",
    "\n",
    "> ```py\n",
    "> df_clean.pivot_table(index=\"rating\", aggfunc=\"count\")\n",
    "> #                    ^^^^^^^^^^^^^^ --- Each row should be one score.\n",
    "> #                                   ^^^^^^^^^^^^^^^ --- Summarize by counting the number of rows\n",
    "> ```\n",
    "\n",
    "Create your first pivot table, and store it in a Python variable `df`, that summarizes your cleaned DataFrame, `df_clean`, by counting the number of films receiving each of the four ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your first pivot table, and store it in a Python variable `df`,\n",
    "# that summarizes your cleaned DataFrame, `df_clean`, by counting the\n",
    "# number of films receiving each of the four ratings:\n",
    "df = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 2.1: Starting a Pivot Table\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert( \"df\" in vars() ), \"You must define a Python variable named `df`.\"\n",
    "assert( len(df) == len(df_clean.rating.unique()) ), \"Your pivot table stored in the variable `df` must have exactly one row for each rating.\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2.2: Creating a Pivot Table for Years\n",
    "\n",
    "Using what you know, create another pivot table.  However, in this new pivot table **summarize the count of how many films are in the dataset for each year** instead each row being a rating.  Just as before, store the pivot table you created in the Python variable `df`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 2.2: Creating a Pivot Table for Years\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert( \"df\" in vars() ), \"You must define a Python variable named `df`.\"\n",
    "assert( len(df) == len(df_clean.year.unique()) ), \"Your pivot table stored in the variable `df` must have exactly one row for each year.\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2.3: Columns in a Pivot Table\n",
    "\n",
    "The pivot table you have just created contains the **count of the number rows with data** for year/column combinations.\n",
    "\n",
    "For example, looking at your pivot table above, if the year `1900` reports **11** for the column `rating`, our pivot table informs us that there were **11** movies in the dataset that contains a data in the column `rating` when the year was `1900`. However, we want to know the breakdown of Bechdel Test scores for those 11 movies.\n",
    "\n",
    "The pivot table you created has two function parameters so far: `index` and `aggfunc`.  The third function parameter we will include is `columns`. The value set for the `columns` parameter will specify what column from the original DataFrame should be presented in each column.  This `columns` value is combined together with the rows value (`index`) we already have specified.\n",
    "\n",
    "Now, create a pivot table with three function parameters:\n",
    "\n",
    "- Each row (`index` parameter) in our pivot table is one year from the original DataFrame,\n",
    "- Each column (`columns` parameter) in our pivot table is one rating from the original DataFrame, **and**\n",
    "- The values are aggregated together by the `\"count\"` function (`aggfunc` parameter).\n",
    "\n",
    "Call this pivot table `df` and we'll check to make sure it looks good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 2.3: Columns in a Pivot Table\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert( len(df) == len(df_clean[\"year\"].unique()) ), \"You should have one row for each year, but your `df` does not. Make sure your `index` parameter is correct.\"\n",
    "assert( len(df.columns) == (len(df_clean.columns) - 2) * 4 ), \"You should have a 0,1,2,3 column for each variable. Make sure your `columns` parameter is correct. \"\n",
    "assert( df[\"id\", 0][2021] == len(df_clean[ (df_clean.year == 2021) & (df_clean.rating == 0) ]) ), \"You have the incorrect number of movies with a 0 rating in 2021. Make sure your `aggfunc` parameter is correct.\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2.4: Adding the `values` Parameter to your Pivot Table\n",
    "\n",
    "In your latest pivot table, you have a summary for the number of movies rated `0`, `1`, `2`, and `3` for every year of data in the dataset, but it is repeated for every `id` record, every `imdbid`, and every `title`.  It's a lot of extra columns! ðŸ˜¢\n",
    "\n",
    "The `values` parameter allows us to specify the columns from the original DataFrame we want to keep in our pivot table.  Currently, we have three columns of data we aren't doing anything specific with except aggregating them together: `id`, `imdbid`, and `title`.  We do not need all three.\n",
    "\n",
    "Since all three columns are identical, it's completely up to you to choose any one of the three columns to keep as the `values` that we're going to analyze.\n",
    "\n",
    "- Do you want to keep the count of how many movies have data for the `id` column in your original dataset?  If so, use `values=\"id\"`.\n",
    "- Do you want to keep the count of how many movies have data for the `imdbid` column in your original dataset?  If so, use `values=\"imdbid\"`.\n",
    "- Do you want to keep the count of how many movies have data for the `title` column in your original dataset?  If so, use `values=\"title\"`.\n",
    "\n",
    "Extend your pivot table to now include all **four** parameters (`index`, `aggfunc`, `columns` and `values`) and store your improved pivot table in the variable `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 2.4: Adding the values Parameter to your Pivot Table\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert( len(df) == len(df_clean[\"year\"].unique()) ), \"You should have one row for each year, but your `df` does not. Make sure your `index` parameter is correct.\"\n",
    "assert( len(df.columns) == 4 ), \"You should have a single 0,1,2,3 column. Make sure your `columns` parameter is correct. \"\n",
    "assert( df[3][2021] == len(df_clean[ (df_clean.year == 2021) & (df_clean.rating == 3) ]) ), \"You have the incorrect number of movies with a 3 rating in 2021. Make sure your `aggfunc` parameter is correct.\"\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 2.5: Specify the `fill_value`\n",
    "\n",
    "Finally, you may notice that there are no movies with a **3** in any of the early 1900s.  Since there is no data for that row/column combination, pandas leaves the value blank and reports a `NaN` or \"Not a Number\".\n",
    "\n",
    "The `fill_value` parameter allows us to give a default value when there is no data.  Since we know no data indicates that there were zero movies that that rating in our dataset, setting `fill_value=0` fills all the missing data with zeroes.  \n",
    "\n",
    "Extend your pivot table to have **five** parameters, ensuring that empty values get replaced with a `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Step 2.5: Specify the fill_value\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "assert( len(df) == len(df_clean[\"year\"].unique()) ), \"You should have one row for each year, but your `df` does not. Make sure your `index` parameter is correct.\"\n",
    "assert( len(df.columns) == 4 ), \"You should have a single 0,1,2,3 column. Make sure your `columns` parameter is correct. \"\n",
    "assert( df[3][2021] == len(df_clean[ (df_clean.year == 2021) & (df_clean.rating == 3) ]) ), \"You have the incorrect number of movies with a 3 rating in 2021. Make sure your `aggfunc` parameter is correct.\"\n",
    "assert( len(df.dropna()) == len(df) ), \"You have some NaN values remaining. Make sure your `fill_value` parameter is correct.\"\n",
    "print(f\"{tada} All tests passed! {tada}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3: Visual Analysis of the Data\n",
    "\n",
    "You have an extremely detailed summary of the entire Bechdel Test dataset -- over 10,000 movies across more than 100 years!  A simple exploratory data visualization would help us understand all of this data and a line chart is a great way to get started!\n",
    "\n",
    "Create a simple line chart by using `df.plot.line()`, no parameters needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 3.1: Transforming Counts into Proportions\n",
    "\n",
    "In the graph above, you can see that the **total number of movies** in the dataset has increased dramatically from the 1900s until today.  However, except for seeing that the number of movies increased, it's impossible to tell if movies are scoring, on average, higher or lower today than they did in the early 1900s.\n",
    "\n",
    "A useful visualization to help determine the change in the promotion of data is a **stacked area chart**.  A stacked area chart is similar to a stacked bar chart where each data value will be stacked on top of the previous data.  The most common application of a stacked area chart is graphing different proportions of data.\n",
    "\n",
    "To create a graph of the proportion of movies at reach ranking, add the following four additional columns to your DataFrame `df`:\n",
    "\n",
    "- `\"%0\"`, that contains the percentage of movies with a `0` ranking in a given year,\n",
    "- `\"%1\"`, that contains the percentage of movies with a `1` ranking in a given year,\n",
    "- `\"%2\"`, that contains the percentage of movies with a `2` ranking in a given year,\n",
    "- `\"%3\"`, that contains the percentage of movies with a `3` ranking in a given year,\n",
    "- *Hint: You may find adding a `\"Total\"` column helpful to make your calculations easier.*\n",
    "\n",
    "Note that the `0`,`1`,`2`,`3` column names are integers, not strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"%0\"] = ...\n",
    "df[\"%1\"] = ...\n",
    "df[\"%2\"] = ...\n",
    "df[\"%3\"] = ...\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 3.1: Transforming Counts into Proportions\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "import math\n",
    "assert( \"%0\" in df.columns ), \"Make sure you have a \\\"%0\\\" column.\"\n",
    "assert( \"%1\" in df.columns ), \"Make sure you have a \\\"%1\\\" column.\"\n",
    "assert( \"%2\" in df.columns ), \"Make sure you have a \\\"%2\\\" column.\"\n",
    "assert( \"%3\" in df.columns ), \"Make sure you have a \\\"%3\\\" column.\"\n",
    "assert( math.isclose( df.loc[2020][\"%0\"], len(df_clean[ (df_clean.year == 2020) & (df_clean.rating == 0) ]) / len(df_clean[ (df_clean.year == 2020) ]) )), \"Your calculation of %0 is incorrect.\"\n",
    "assert( math.isclose(df.loc[2019][\"%1\"], len(df_clean[ (df_clean.year == 2019) & (df_clean.rating == 1) ]) / len(df_clean[ (df_clean.year == 2019) ]))), \"Your calculation of %1 is incorrect.\"\n",
    "assert( math.isclose(df.loc[2018][\"%2\"], len(df_clean[ (df_clean.year == 2018) & (df_clean.rating == 2) ]) / len(df_clean[ (df_clean.year == 2018) ]))), \"Your calculation of %2 is incorrect.\"\n",
    "assert( math.isclose(df.loc[2017][\"%3\"], len(df_clean[ (df_clean.year == 2017) & (df_clean.rating == 3) ]) / len(df_clean[ (df_clean.year == 2017) ]))), \"Your calculation of %3 is incorrect.\"\n",
    "print(f\"{tada} All tests passed! {tada}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 3.2: Finding the Percentage of Movies Per Year with Each Rating:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "To visualize only the percentage columns, create a new `df_pct` that contains only the `%0`, `%1`, `%2`, and `%3` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct = ...\n",
    "df_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST CASE for Part 3.2: Finding the Percentage of Movies Per Year with Each Rating\n",
    "tada = \"\\N{PARTY POPPER}\"\n",
    "\n",
    "assert( \"df_pct\" in vars() ), \"Make sure you have defined the DataFrame `df_pct`.\"\n",
    "assert( \"%0\" in df_pct.columns ), \"Make sure you have a \\\"%0\\\" column.\"\n",
    "assert( \"%1\" in df_pct.columns ), \"Make sure you have a \\\"%1\\\" column.\"\n",
    "assert( \"%2\" in df_pct.columns ), \"Make sure you have a \\\"%2\\\" column.\"\n",
    "assert( \"%3\" in df_pct.columns ), \"Make sure you have a \\\"%3\\\" column.\"\n",
    "assert( len(df_pct.columns) == 4 ), \"Make sure you only have the percentage columns in `df_pct`.\"\n",
    "\n",
    "print(f\"{tada} All tests passed! {tada}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part 3.3: Visualizing the Percentage of Movies / Year with Each Rating:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Since `df_pct` has rows that always add up to `1`, this data is **PERFECT** for a stacked area graph.  In the cell below, `df.plot.area()` is used to create a stacked area visualization to view the growth of the percentage of each movie's rating. Run the cell to view the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct.plot.area(figsize=(10,5), title=\"Percentage of Movies with Each Bechdel Test Score Per Year\", colormap=\"RdPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Area Chart Analysis\n",
    "\n",
    "The stacked area chart shows the proportion of movies with a score of `0`, `1`, `2`, and `3`. Here are some questions to think about:\n",
    "- Has the proportion of movies rated as `3` generally increased over the past century?\n",
    "- Were there periods of time where the general trend reversed?\n",
    "\n",
    "And feel free to nerd out with this visualization:\n",
    "- You can change the colors used in this visualization, and any other visualization, by changing the `colormap` parameter.  The page [Choosing Colormaps in Matplotlib](https://matplotlib.org/stable/users/explain/colors/colormaps.html) lists all of the available colormaps included with pandas!\n",
    "- Feel free to add `grid=True`, which will help with data analysis as it is well known that it's tricky for humans to imagine a straight line when the background is slanted.  (It's really crazy how different the data looks with grid lines turned on!)\n",
    "- Finally, you're free to change this graph an any other way you want! It's your graph to transform! :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "<hr style=\"color: #DD3403;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission\n",
    "\n",
    "You're almost done!  All you need to do is to commit your lab to GitHub and run the GitHub Actions Grader:\n",
    "\n",
    "1.  âš ï¸ **Make certain to save your work.** âš ï¸ To do this, go to **File => Save All**\n",
    "\n",
    "2.  After you have saved, exit this notebook and return to https://discovery.cs.illinois.edu/microproject/bechdel-test/ and complete the section **\"Commit and Grade Your Notebook\"**.\n",
    "\n",
    "3. If you see a 100% grade result on your GitHub Action, you've completed this MicroProject! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
